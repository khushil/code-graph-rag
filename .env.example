# Gemini settings
GEMINI_API_KEY=your-gemini-api-key
GEMINI_MODEL_ID=gemini-2.5-pro
MODEL_CYPHER_ID=gemini-2.5-flash-lite-preview-06-17

# OpenAI settings
OPENAI_API_KEY=your-openai-api-key
OPENAI_ORCHESTRATOR_MODEL_ID=gpt-4o-mini
OPENAI_CYPHER_MODEL_ID=gpt-4o-mini

# Anthropic settings
ANTHROPIC_API_KEY=your-anthropic-api-key
ANTHROPIC_ORCHESTRATOR_MODEL_ID=claude-3-5-sonnet-20241022
ANTHROPIC_CYPHER_MODEL_ID=claude-3-5-haiku-20241022

# Local model settings
# Example for Ollama:
LOCAL_MODEL_ENDPOINT="http://localhost:11434/v1"
LOCAL_ORCHESTRATOR_MODEL_ID="llama3"
LOCAL_CYPHER_MODEL_ID="llama3"
LOCAL_MODEL_API_KEY="ollama" # Ollama uses "ollama" as a placeholder

MEMGRAPH_HOST=localhost
MEMGRAPH_PORT=7687
MEMGRAPH_HTTP_PORT=7444
LAB_PORT=3000
TARGET_REPO_PATH=.
